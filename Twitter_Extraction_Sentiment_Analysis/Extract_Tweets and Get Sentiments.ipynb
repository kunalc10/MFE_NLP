{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "from string import ascii_letters, digits\n",
    "from os import mkdir, path\n",
    "import twint\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def clean_name(dirname):\n",
    "    valid = set(ascii_letters + digits)\n",
    "    return ''.join(a for a in dirname if a in valid)\n",
    "\n",
    "\n",
    "def twint_search(searchterm, since, until, json_name):\n",
    "    '''\n",
    "    Twint search for a specific date range.\n",
    "    Stores results to json.\n",
    "    '''\n",
    "    c = twint.Config()\n",
    "    c.Search = searchterm\n",
    "    c.Since = since\n",
    "    c.Until = until\n",
    "    c.Hide_output = True\n",
    "    c.Store_json = True\n",
    "    c.Output = json_name\n",
    "   \n",
    "    try:\n",
    "        twint.run.Search(c)    \n",
    "    except (KeyboardInterrupt, SystemExit):\n",
    "        raise\n",
    "    except:\n",
    "        print(\"Problem with %s.\" % since)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def twint_loop(searchterm, since, until, tag_name = ''):\n",
    "\n",
    "    dirname = clean_name(searchterm)\n",
    "    dirname = dirname\n",
    "    try:\n",
    "    # Create target Directory\n",
    "        mkdir(dirname)\n",
    "        print(\"Directory\" , dirname ,  \"Created \")\n",
    "    except FileExistsError:\n",
    "        print(\"Directory\" , dirname ,  \"already exists\")\n",
    "    \n",
    "    \n",
    "    daterange = pd.date_range(since, until)\n",
    "\n",
    "    i = 1\n",
    "    for start_date in daterange:\n",
    "\n",
    "        since= start_date.strftime(\"%Y-%m-%d\")\n",
    "        until = (start_date + timedelta(days=2)).strftime(\"%Y-%m-%d\")\n",
    "        i = i+1\n",
    "\n",
    "        json_name = tag_name + '%s.json' % since\n",
    "        json_name = path.join(dirname, json_name)\n",
    "\n",
    "        print('Getting %s ' % since )\n",
    "        twint_search(searchterm, since, until, json_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "twint_loop('#bumble', '7-01-2020', '09-30-2020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "from glob import glob\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge the json to single DF\n",
    "from glob import glob\n",
    "\n",
    "file_names = glob(path.join('','*.json'))\n",
    "dfs = [pd.read_json(fn, lines = True) for fn in file_names]\n",
    "bumble_df = pd.concat(dfs)\n",
    "\n",
    "bumble_df['tweet']\n",
    "bumble_df.head()\n",
    "tweets = pd.DataFrame(bumble_df[['tweet','date']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tweets_temp = pd.DataFrame(bumble_df[['tweet','date']])\n",
    "tweets['Year'] = tweets.date.map(lambda x : x.strftime('%Y'))\n",
    "tweets['month'] = tweets.date.map(lambda x : x.strftime('%m'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert all to uppercase\n",
    "tweets['tweet'] = tweets['tweet'].str.upper()\n",
    "#filter the text for #Bumble and @Bumble\n",
    "bumble_rate = tweets[tweets['tweet'].str.contains('@BUMBLE ') == True]\n",
    "bumble_hash = tweets[tweets['tweet'].str.contains('#BUMBLE ') == True]\n",
    "\n",
    "#Clean the test\n",
    "def cleanTxt(text):\n",
    "    text =  re.sub(r'@[A-Za-z0-9]+' , '', text) # removed @ mentions\n",
    "    text =  re.sub(r'#' , '', text) # removed # mentions\n",
    "    text =  re.sub(r'RT[\\s]' , '', text) # removed RT\n",
    "    text =  re.sub(r'https?:\\/\\/\\S+' , '', text) # removed web url\n",
    "    text =  re.sub(r'HTTPS?:\\/\\/\\S+' , '', text) # removed web url\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.concat([bumble_rate , bumble_hash])\n",
    "tweets = tweets.drop_duplicates()\n",
    "tweets['CleanTweet'] = tweets['tweet'].apply(cleanTxt)\n",
    "df = pd.concat([bumble_rate , bumble_hash])\n",
    "df = df.drop_duplicates(subset = [\"tweet\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to get subjectivity\n",
    "def getSubjectivity(text):\n",
    "    return TextBlob(text).sentiment.subjectivity\n",
    "\n",
    "#create a function to get polarity\n",
    "def getPolarity(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "tweets['polarity'] = tweets['CleanTweet'].apply(getPolarity)\n",
    "tweets['subjectivity'] = tweets['CleanTweet'].apply(getSubjectivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to compute the -ve , neutral and +ve analysis\n",
    "def getAnalysis(score):\n",
    "    if score < 0:\n",
    "        return 'Negative'\n",
    "    elif score == 0:\n",
    "        return 'Neutral'\n",
    "    elif score > 0:\n",
    "        return 'Positive'\n",
    "tweets['Analysis'] = tweets['polarity'].apply(getAnalysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aggregated = tweets.groupby(['month','Year','Analysis']).count()\n",
    "df_aggregated.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the polarity and subjectivity\n",
    "plt.figure(figsize = (8,6))\n",
    "for i in range(0,tweets.shape[0]):\n",
    "    plt.scatter(tweets['polarity'][i], tweets['subjectivity'][i], color = 'Blue')\n",
    "plt.xlabel('Polarity')\n",
    "plt.ylabel('Subjectivity')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot skewed to right (positive)\n",
    "# Get count of positive tweet\n",
    "plt.title('Sentiment Analysis')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Counts')\n",
    "tweets['Analysis'].value_counts().plot(kind = 'bar')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
